---
title: "37-cEOF DAMIP"
author: "Elio Campitelli"
output: 
   bookdown::html_document2:
         base_format: tufte::tufte_html 
link-citations: yes 
params:
   season: "SON"
---


```{r setup, include=FALSE}
# Notification
start.time <- unclass(Sys.time())
min.time <- 10
knit_doc <- knitr::knit_hooks$get("document")

options(htmltools.dir.version = FALSE)
# knitr::knit_hooks$set(document = function(x) {
#    took <- unclass(Sys.time()) - start.time
#    if (unclass(Sys.time()) - start.time >= min.time) {
#       notify("Done knitting!", 
#              paste0("Took ", round(took), " seconds"),
#              time = 5)
#    }  
#    knit_doc(x)
# })


# name <- tools::file_path_sans_ext(knitr::current_input())
name <- "37-cEOF-DAMIP"
knitr::opts_chunk$set(
   echo = FALSE,
   fig.path = paste0("fig/", name, "/"),
   message = TRUE,
   warning = FALSE,
   message = FALSE,
   cache = TRUE, 
   cache.lazy = FALSE,
   cache.extra = 41,
   cache.path = paste0("cache/", name, "/")
)

knitr::opts_hooks$set(label = function(options) {
   if (is.null(options$fig.cap)) {
      options$fig.cap <- paste0("(ref:", options$label, "-cap)")
   }
   options
})

cache <- cachem::cache_disk(file.path("cache", name, "memoise"))

library(data.table)
library(magrittr)
library(ggplot2)
library(metR)
library(gt)
library(tagger)
library(tidyfast)
library(rcmip6)
source("scripts/fftspectrum.R")
source("scripts/helperfun.R")
D <- `[`

factor_ReIm <- function(part) {
   factor(part, levels = c("Real", "Imaginary"), ordered = TRUE)
}

ReIm <- function(complex) {
   list(Real = Re(complex), Imaginary = Im(complex))
}

sep_ReIm <- function(data, column, format = c("longer", "wider")) {
   R <- part <- I <- NULL
   names <- c("Real", "Imaginary")
   
   
   if (missing(column)) {
      complex <- vapply(data, function(x) inherits(x, "complex"), TRUE)
      if (sum(complex) > 1) {
         stop("`column` missing and more than one complex column found")
      }
      if (sum(complex) == 0) {
         warning("`column` missing and no complex column found. Returning unchanged data")
         return(data)
      }
      
      col <- colnames(data)[complex]
   } else {
      col <- deparse(substitute(column))
   }
   
   
   data <- data.table::copy(data)[, (names) := ReIm(get(col))]
   
   
   if (format[1] == "longer") {
      data[, c(col) := NULL]
      data <- data.table::setDT(tidyr::pivot_longer(data, Real:Imaginary, names_to = "part", values_to = col))
      data[, part := factor(part, levels = names, ordered = TRUE)]
   }
   
   return(data[])
}

source("scripts/theme.R")
theme_set(theme_elio())
guide_colorstrip_bottom <- function(width = 25, height = 0.5, ...) {
   ggplot2::guide_colorstrip(title.position = "top", title.hjust = 0.5,
                             barheight = height,
                             barwidth = width, ...)
}

sink <- capture.output(sf::sf_use_s2(FALSE))
geom_qmap <- function(subset = identity,
                      crop = NULL,
                      color = "gray50", size = 0.3,
                      fill = NA, wrap = c(0, 360), weighting = 0.7,
                      keep = 0.015, ...) {
   lon <- lat <- group <- NULL
   data <- map_simple(wrap = wrap, keep  = keep, weighting = weighting)
   
   if (!is.null(crop)) {
      bbox <- sf::st_bbox(data)
      
      for (n in names(crop)) {
         bbox[[n]] <- crop[[n]]
      }
      
      data <- suppressWarnings(suppressMessages(sf::st_crop(data, bbox)))
   }
   
   
   subset <- purrr::as_mapper(subset)
   data <- subset(data)
   
   ggplot2::geom_sf(data = data,
                    inherit.aes = FALSE,
                    color = color,
                    size = size,
                    fill = fill,
                    ...)
   
}

map_simple <- function(wrap = c(0, 360), keep = 0.015, weighting = 0.7) {
   map <- maps::map("world", fill = TRUE,
                    col = "transparent", plot = FALSE, wrap = wrap)
   map <- sf::st_as_sf(map)
   if (keep != 1) {
      map <- rmapshaper::ms_simplify(map, keep = keep, weighting = weighting)
   }
   
   
   map
}

height <- GetTopography(0, 180-1.5, 10.5, -89, resolution = 1.5,
                        file.dir = file.path("cache", name, "topo")) %>% 
   rbind(GetTopography(180+1.5, 360, 10.5, -89, resolution = 1.5,
                       file.dir = file.path("cache", name, "topo"))) %>% 
   as.data.table()


coord_polar <- function(ymax = -20, ...) {
   
   x <- c(seq(0, 360, length.out = 40), 
          seq(360, 0, length.out = 40), 
          0)
   y <- c(rep(ymax, length.out = 40), 
          rep(60, length.out = 40), 
          ymax)
   
   cbind(x, y) %>% 
      list() %>% 
      sf::st_polygon() %>% 
      sf::st_sfc(crs = "+proj=latlong") -> white
   
   list(
      geom_sf(data = white, inherit.aes = FALSE, 
              fill = "white", 
              colour = "white", size = 2),
      coord_sf(ylim = c(-90, ymax), 
               lims_method = "box",
               crs = "+proj=laea +lat_0=-90",
               default_crs = "+proj=longlat",
               label_axes =  "----", ...)
   )
}

periodic_lon <- function(data) {
   m_lon <- min(data$lon)
   range <- c(0, 360) + m_lon
   range2 <- c(0 - m_lon, 360) 
   
   ggperiodic::periodic(data, lon = range) %>% 
      ggperiodic::wrap(lon = range2)
}


n_eof <- 2

climatology <- as.Date(c("1985-01-01", "2014-12-31"))

is.enso34 <- function(lon, lat) {
   (abs(lat) < 5) & (ConvertLongitude(lon) %between% c(-170, -120))
}
```



```{r cmip_available}
# Tuve que optimizar algunas cosas para poder parsear miles de archivos
cmip_available <- function(..., root = cmip_root_get()) {
   
   template <- rcmip6:::cmip6_folder_template %>% 
      gsub("\\%\\(", "{", .) %>% 
      gsub("\\)s", "}", .)
   
   vars <- template %>% 
      gsub("\\{", "", .) %>% 
      gsub("\\}", "", .) %>% 
      strsplit("/") %>% 
      .[[1]]
   
   search_null <- rep("*", length(vars)) %>% 
      setNames(vars) %>% 
      as.list()
   
   globulate <- function(x) {
      if (length(x) > 1) {
         paste0("@(", paste0(unique(x), collapse = "|"), ")")   
      } else {
         x
      }
   }
   
   search <- list(...)
   for (name in names(search)) {
      search_null[[name]] <- search[[name]]
   }
   search <- search_null
   
   search <- lapply(search, globulate)
   search$root <- root
   
   # Hay que asegurarse de correr en bash
   command <- paste0("shopt -s extglob\n ls -f ", 
                     paste0(glue::glue_data(search, template), "/model.info"))
   script_file <- tempfile()
   writeLines(command, script_file)
   
   info <- system(paste0("/bin/bash  ", script_file), intern = TRUE)
   
   info <- normalizePath(info)
   
   data <- unglue::unglue_data(gsub(cmip_root_get(), "", dirname(info)),
                               gsub("\\{root\\}/", "", template))
   
   
   files <- lapply(info, function(info) {
      Sys.glob(paste0(dirname(info), "/*nc"))
   })
   data$files <- files
   
   return(data)
}
```


```{r sims}
cmip_root_set("/shera/datos/CMIP/")
experiments <- c("hist-GHG", "hist-stratO3", "hist-nat")
sims <- cmip_available(mip_era = "CMIP6", 
                       activity_drs = "DAMIP",
                       experiment_id = experiments,
                       # source_id = unique(simulaciones$model),
                       table_id = c("Amon"),
                       variable_id = c("zg")) %>% 
   as.data.table() %>% 
   .[, version := as.numeric(version)] %>% 
   .[, c("ensemble", "init", "physics", "forcing") := as.list(unglue::unglue_data(member_id, "r{ensemble}i{init}p{physics}f{forcing}", convert = TRUE))] %>% 
   .[order(ensemble)]


# Me quedo con los modelos con todos los experimentos
sims <- sims[, .SD[all(experiments %in% experiment_id)], by = .(source_id)]
```


```{r select_merge}
future::plan("multisession", workers = 10)
select_merge <- function(file_in) {
   
   unique_items <- file_in %>% 
      basename() %>% 
      unglue::unglue_data("{variable}_{mean}_{model}_{experiment}_r{member}i{init}p{physics}f{forcing}_{grid}_{start_date}-{end_date}.nc") %>% 
      as.data.table() %>% 
      .[, ":="(start_date = NULL, end_date = NULL)] %>% 
      unique() %>% 
      nrow()
   
   browser(expr = unique_items != 1)
   # stopifnot(unique_items == 1)
   
   file_out <- file.path("damip", params$season, basename(file_in[1]))
   dir.create(dirname(file_out), showWarnings = FALSE, recursive = TRUE)
   if (file.exists(file_out)) {
      message(paste0("Skipping existing file ", basename(file_in[1])))
      return(file_out)
   }
   
   # Hay algunos archivos mal bajados. 
   nulos <- file.size(file_in) == 0
   if (any(nulos)) {
      warning("Archivo(s) nulos: \n", paste0(file_in[nulos], collapse = "\n"))
      return(NA_character_)
   }
   message("Procesando archivos ", basename(file_in[1]))
   var <- substr(basename(file_in[1]), 1, 1) 
   
   # Algunos modelos (IPSL) vienen con una grilla "genérica" en vez de lonlat
   to_regrid <- FALSE
   if (var == "t") {
      grid <- tempfile()
      invisible(capture.output(t <- system(paste0("cdo griddes ", file_in[1], " > ", grid), intern = TRUE)))
      if (length(grep("generic", readLines(grid))) != 0) {
         to_regrid <- TRUE
         invisible(capture.output(t <- system(paste0('sed -i "s/generic/lonlat/g" ', grid), intern = TRUE)))
      }
   }  
   
   
   # Selecciondo para cada archivito
   # TODO: hacer un hard stop si falla algún archivo. 
   # https://twitter.com/UbuntR314/status/1523761710548406272
   temp_files <- furrr::future_map_chr(file_in, function(file) {
      file_out <- tempfile(fileext = ".nc")
      
      if (to_regrid) {
         outfile <- tempfile(fileext = ".nc")
         invisible(capture.output(t <- system(paste0("cdo setgrid,", grid, " ", file, " ", outfile))))
         file <- outfile
      }
      if (var == "z") {
         select <- "-sellevel,20000,5000"
         remap <- NULL
      } else {
         select <- NULL
         # Paso sst a una grilla regular porque sino distintos modelos tienen distintas
         # grillas y es un quilombo procesarlos programáticamente.
         remap <- "-remapdis,r240x60" 
      }
      
      s <- capture.output(system(paste0("cdo ", select, " -timselmean,3 -select,season=SON ",
                                        remap, " ", 
                                        shQuote(file), " ", 
                                        shQuote(file_out)), 
                                 intern = TRUE))
      if (!file.exists(file_out)) {
         file_out <- NA_character_
      }
      
      return(file_out)
   })
   
   # y luego uno
   s <- system(paste0("cdo mergetime ", paste0(shQuote(temp_files), collapse = " "), " ",
                      shQuote(file_out)))
   
   if (s == 1) {
      return(NA_character_)
   }
   unlink(temp_files)
   return(file_out)
}
```


```{r merge}
files <- sims$files %>% 
   vapply(select_merge, character(1))
```


```{r simulaciones}
simulaciones <- na.omit(files) %>% 
   basename() %>% 
   unglue::unglue_data("{variable}_{mean}_{model}_{experiment}_r{member}i{init}p{physics}f{forcing}_{grid}_{start_date}-{end_date}.nc", convert = TRUE) %>% 
   as.data.table() %>% 
   DT(, file := na.omit(files)) %>% 
   DT(order(variable, model, member, experiment))
```


```{r descripcion}
simulaciones %>% 
   .[, .(miembros = .N), by = .(model, experiment)] %>% 
   .[order(-miembros)] %>% 
   dcast(model ~ experiment, value.var = "miembros", fill = 0) %>% 
   knitr::kable(caption = "Modelos disponibles.")
```


```{r}
cmip_ceofs <- readRDS(file.path("cmip", params$season, "cmip6_ceofs.Rds"))
cmip_ceofs_largo <- readRDS(file.path("cmip", params$season, "cmip6_ceofs_largo_p.Rds"))

```

```{r}
Detrend2 <- function(x) {
   y <- seq_along(x)
   .lm.fit(cbind(1, y, y^2), x)$residuals + mean(x)
}

grid <- expand.grid(lon = seq(0, 360, by = 2.5),
                    lat = seq(-90, 0, by = 2.5))


interpolate_to_era <- function(data, formula = eof ~ lon + lat) {
   Interpolate(formula, x.out = unique(grid$lon), y.out = unique(grid$lat), 
               data = pad_longitudes(data)) 
}

pad_longitudes <- function(data) {
   left <- right <- NULL
   rlon <- ggplot2::resolution(data$lon, zero = FALSE)
   mlon <- min(data$lon)
   Mlon <- max(data$lon)
   
   if (mlon > 0) {
      left <- data[lon == Mlon] %>% 
         DT(, lon := mlon - rlon)
   }   
   
   if (Mlon < 357.5) {
      right <- data[lon == mlon] %>% 
         DT(, lon := Mlon + rlon) 
   }
   
   rbind(left, 
         data, 
         right) 
}
```

```{r rotate_eof}
weighted_correlation <- function(x, y, w) {
   cov.wt(cbind(x, y), wt = w, cor = TRUE)$cor[1, 2]
}

rotate <- function(z, angle = 0) {
   complex(real = cos(angle), imaginary = sin(angle)) * z
}

rotate_eof <- function(eof, angle) {
   eof <- copy(eof)
   eof$right <- eof$right[angle, on = "cEOF", ][, eof := rotate(eof, angle)][, angle := NULL]
   eof$left <- eof$left[angle, on = "cEOF", ][, eof := rotate(eof, angle)][, angle := NULL]
   eof
}
```

```{r optimise_rotation}

ref_era5 <- cmip_ceofs %>% 
   .[model == "ERA5"] %>% 
   .[, eof[[1]]$right] %>%
   copy() %>% 
   setnames("eof", "eof_ref")

optimise_rotation <- function(eof, ref = ref_era5) {
   angles <- seq(-pi, pi, by = 0.5*pi/180)
   
   joined <- eof$right %>% 
      pad_longitudes() %>% 
      DT(, Interpolate(eof ~ lon + lat, x.out = unique(ref$lon), y.out = unique(ref$lat)), 
         by = .(cEOF, lev)) %>% 
      DT(ref, on = .NATURAL) %>% 
      na.omit()
   
   cors <- lapply(angles, function(a) {
      joined %>% 
         DT(, eof2 := rotate(eof, a)) %>% 
         DT(, .(correlation = weighted_correlation(Re(eof2), Re(eof_ref), cos(lat*pi/180))), 
            by = .(cEOF)) %>% 
         DT(, angle := a) 
   }) %>% 
      rbindlist()
   
   best_cor <- cors[, .SD[which.max(correlation)], by = cEOF]
   eof <- rotate_eof(eof, best_cor[, .(cEOF, angle)])
   
   eof$sdev <- eof$sdev[best_cor[, .(cEOF, correlation, angle)], on = "cEOF"]
   eof
}
```


```{r compute_eof}
compute_eof_ <- function(files, member, time = c("1979-10-01", "2014-12-31"), detrend = FALSE) {
   message("procesando ", files[1])
   
   array <- lapply(files, function(file) {
      ReadNetCDF(file, vars = c(hgt = "zg"), 
                 subset = list(lat = c(-85, -20),
                               time = time),
                 out = "array")[[1]]
   })
   
   time_lookup <- data.table::data.table(time = dimnames(array[[1]])$time,
                                         time_date = as.integer(year(attr(array[[1]], "dimvalues")$time)))
   
   array <- abind::abind(array, rev.along = 0,
                         use.dnns = TRUE)
   
   dimnames(array)[[5]] <- member
   names(dimnames(array))[[5]] <- "ensemble"
   
   
   whichdim <- function(array, dims) {
      which((names(dimnames(array)) %in% dims))
   }
   whichdimnot <- function(array, dims) {
      which(!(names(dimnames(array)) %in% dims))
   }
   
   # Calcular anomalias zonales
   array <- apply(array, whichdimnot(array, "lon"), Anomaly) %>% 
      aperm(names(dimnames(array)))
   
   if (detrend) {
      # Detrend
      ensemble_mean <- rowMeans(array, dims = 4)
      trend <- apply(ensemble_mean, c("lon", "lat", "plev"), function(x) {
         time <- seq_along(x)
         x - .lm.fit(cbind(1, time, time^2), x)$residuals - mean(x)
      }) %>% 
         aperm(names(dimnames(array))[-5])
      
      array <- sweep(array, 1:4, trend)
   }
   
   
   # Estandarizar
   sd <- apply(array, "plev", sd)
   array <- sweep(array, whichdim(array, "plev"), sd, FUN = "/")
   
   # Transfomar de hilbert
   hilbert <- apply(array, whichdimnot(array, "lon"), spectral::analyticFunction) %>% 
      aperm(names(dimnames(array)))
   
   hilbert <- aperm(hilbert, setNames(seq_along(dimnames(hilbert)), 
                                      names(dimnames(hilbert)))[c("time", "ensemble", "lon", "lat", "plev")])
   
   # Calcular EOF y hacer tidy
   dim(hilbert) <- list(prod(lengths(dimnames(hilbert))[1:2]),
                        prod(lengths(dimnames(hilbert))[3:5]))
   
   eof <- irlba::irlba(hilbert, 2, 2)
   
   dim(eof$u) <-  as.list(c(dimnames(array)[c("time", "ensemble")] %>% lengths(),
                            eof = 2))
   dimnames(eof$u) <- with(dimnames(array), 
                           list(time = time, ensemble = ensemble, cEOF = 1:2))
   eof$u <- reshape2::melt(eof$u, value.name = "eof") %>% data.table::setDT()
   eof$u[, time := as.character(time)]
   
   eof$u <- time_lookup[eof$u, on = .NATURAL] %>% 
      DT(, time := NULL) %>% 
      data.table::setnames("time_date", "time")
   eof$u[, cEOF := factor(paste0("cEOF", cEOF))]
   
   dim(eof$v) <- as.list(c(c(dimnames(array)[c("lon", "lat", "plev")] %>% lengths(),
                             eof = 2)))
   dimnames(eof$v) <- with(dimnames(array),
                           list(lon = lon, lat = lat, lev = plev, cEOF = 1:2))
   
   eof$v <- reshape2::melt(eof$v, value.name = "eof") %>%  data.table::setDT()
   eof$v[, cEOF := factor(paste0("cEOF", cEOF))]
   eof$v[, lat := as.numeric(lat)]
   eof$v[, lon := as.numeric(lon)]
   eof$v[, lev := as.integer(lev/100)]
   
   variance <- norm(abs(hilbert), type = "F")
   
   eof$d <- data.table(cEOF = factor(paste0("cEOF", 1:2), levels = paste0("cEOF", 1:2),
                                     ordered = TRUE), 
                       sd = eof$d, 
                       r2 = eof$d^2/variance^2)
   
   return(structure(
      list(left = eof$u, 
           right = eof$v, 
           sdev = eof$d),
      call = match.call(), 
      class = c("eof", "list"), 
      suffix = "cEOF", 
      value.var = "eof"))
}

compute_eof <- memoise::memoise(compute_eof_, cache = cache)
```


```{r}
cmip_ceofs[, experiment := "hist"]
```

```{r}
ceofs <- simulaciones %>% 
   .[variable == "zg"] %>%
   .[, .(eof = list(compute_eof(file, member, time = c(NA, NA)) %>%
                       optimise_rotation())), 
     by = .(model, experiment)]

ceofs <- rbind(ceofs, cmip_ceofs[model %in% ceofs$model][, experiment := "hist"])
```


```{r plot_ceof} 
plot_ceof <- function(data, n, which_lev = 200) {
   data <- data[, .(eof = list(cut(eof[[1]], n))), by = model]
   
   which_pc <- paste0("cEOF", n)
   
   models <- data %>% 
      DT(, eof[[1]]$sdev, by = model) %>%
      DT(cEOF == which_pc) %>% 
      DT(order(-correlation)) 
   
   labels <- models %>%
      DT(, setNames(paste0(model, "\n(", scales::number(correlation^2, 0.01), ")"),
                    model))
   
   data %>% 
      DT(, eof[[1]]$right, by = model) %>%
      # DT(, denormalise(eof[[1]], "right"), by = model) %>%
      DT(cEOF == which_pc) %>% 
      # DT(, eof[[1]]$right, by = model) %>%
      DT(, model := factor(model, levels = models$model)) %>%
      DT(lev == which_lev) %>% 
      DT(, eof := eof/max(Mod(eof)), by = model) %>% 
      DT(, interpolate_to_era(.SD), by = .(model, lev, cEOF)) %>% 
      # DT(, eof := eof/sd(eof), by = .(model)) %>% 
      ggperiodic::periodic(lon = c(0, 360)) %>% 
      ggplot(aes(lon, lat)) +
      geom_contour_fill(aes(z = Re(eof)), breaks = AnchorBreaks(exclude = 0)) +
      geom_contour2(aes(z = Im(eof), linetype = factor(-sign(..level..))), 
                    breaks = AnchorBreaks(exclude = 0)) +
      scale_linetype(guide = "none") +
      scale_fill_divergent(guide = "none") +
      geom_qmap(crop = c(ymax = -20)) +
      scale_x_longitude() +
      scale_y_latitude(limits = c(-90, NA)) +
      coord_polar() +
      facet_wrap(model ~., labeller = labeller(model = labels))
   
}
```



```{r cors}
cors <- ceofs %>% 
   DT(, eof[[1]]$sdev, by = .(experiment, model)) %>% 
   # DT(model != "ERA5") %>% 
   copy() %>% 
   DT(, r2 := correlation^2) %>% 
   DT(, label := paste0(model, "\n(", scales::number(correlation^2, 0.01), ")"))
```


```{r}
cors %>% 
   DT(model != "ERA5") %>% 
   DT(, model := reorder(model, r2, fun = mean)) %>% 
   ggplot(aes(r2, model)) +
   geom_col(aes(fill = experiment),
            position = "dodge") +
   scale_fill_brewer(palette = "Set1") +
   scale_x_continuous("R^2 espacial", limits = c(0, 1)) +
   scale_y_discrete(NULL) +
   labs(caption = "Con tendencia") +
   facet_wrap(~cEOF)
```


```{r}
ceofs %>% 
   .[experiment != "hist"] %>% 
   .[, eof[[1]]$left, by = .(model, experiment)] %>% 
   # rbind(copy(cmip_ceofs_largo)[, experiment := "hist"], fill = TRUE) %>%
   sep_ReIm() %>% 
   ggplot(aes(time, eof)) +
   # geom_line(aes(color = experiment, 
   #               group = interaction(experiment, model, ensemble)), 
   #           alpha = 0.1) +
   geom_smooth(aes(color = experiment, group = interaction(experiment, model))) +
   facet_grid(cEOF~part)
```


